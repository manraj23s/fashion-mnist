{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Load Fashion-MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Normalize the data\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# Convert class labels to one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "def make_and_fit_cnn():\n",
        "    inputs = Input(shape=(28, 28, 1))\n",
        "\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=predictions)\n",
        "    model.compile(optimizer=optimizers.Adam(1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    clr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_delta=0.01,\n",
        "        cooldown=0,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1)\n",
        "\n",
        "    model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=256,\n",
        "        epochs=10,\n",
        "        shuffle=True,\n",
        "        validation_data=(x_test, y_test),\n",
        "        callbacks=[clr])\n",
        "\n",
        "    return model\n",
        "\n",
        "cnn_model = make_and_fit_cnn()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TZMs3wON-Hw",
        "outputId": "c22766fb-1ec5-4d6e-efe7-c7b8d16ab7dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 14, 14, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 14, 14, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 7, 7, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 3136)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               401536    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 422,026\n",
            "Trainable params: 421,834\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 2s 5ms/step - loss: 0.5017 - accuracy: 0.8254 - val_loss: 2.6846 - val_accuracy: 0.2529 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.3340 - accuracy: 0.8809 - val_loss: 0.6178 - val_accuracy: 0.7695 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2816 - accuracy: 0.8983 - val_loss: 0.3074 - val_accuracy: 0.8848 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2501 - accuracy: 0.9084 - val_loss: 0.2451 - val_accuracy: 0.9119 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2241 - accuracy: 0.9184 - val_loss: 0.2443 - val_accuracy: 0.9116 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.2021 - accuracy: 0.9262 - val_loss: 0.2874 - val_accuracy: 0.8983 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "232/235 [============================>.] - ETA: 0s - loss: 0.1898 - accuracy: 0.9290\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1902 - accuracy: 0.9288 - val_loss: 0.2434 - val_accuracy: 0.9176 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1517 - accuracy: 0.9432 - val_loss: 0.2314 - val_accuracy: 0.9247 - lr: 5.0000e-04\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1364 - accuracy: 0.9489 - val_loss: 0.2278 - val_accuracy: 0.9276 - lr: 5.0000e-04\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1266 - accuracy: 0.9527 - val_loss: 0.2424 - val_accuracy: 0.9251 - lr: 5.0000e-04\n"
          ]
        }
      ]
    }
  ]
}